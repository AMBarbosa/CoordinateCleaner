<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Tutorial - Cleaning GBIF data for the use in biogeography • CoordinateCleaner</title>
<!-- jquery --><script src="https://code.jquery.com/jquery-3.1.0.min.js" integrity="sha384-nrOSfDHtoPMzJHjVTdCopGqIqeYETSXhZDFyniQ8ZHcVy08QesyHcnOUpMpqnmWq" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script><!-- Font Awesome icons --><link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous">
<!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/1.7.1/clipboard.min.js" integrity="sha384-cV+rhyOuRHc9Ub/91rihWcGmMmCXDeksTtCihMupQHSsi8GIIRDG0ThDc3HGQFJ3" crossorigin="anonymous"></script><!-- sticky kit --><script src="https://cdnjs.cloudflare.com/ajax/libs/sticky-kit/1.1.3/sticky-kit.min.js" integrity="sha256-c4Rlo1ZozqTPE2RLuvbusY3+SU1pQaJC0TjuhygMipw=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script><meta property="og:title" content="Tutorial - Cleaning GBIF data for the use in biogeography">
<meta property="og:description" content="">
<meta name="twitter:card" content="summary">
<!-- mathjax --><script src="https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <div class="container template-article">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">CoordinateCleaner</a>
        <span class="label label-default" data-toggle="tooltip" data-placement="bottom" title="Released package">2.0.1</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../index.html">
    <span class="fa fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/Cleaning_GBIF_data_with_CoordinateCleaner.html">Tutorial - Cleaning GBIF data for the use in biogeography</a>
    </li>
    <li>
      <a href="../articles/Cleaning_PBDB_fossils_with_CoordinateCleaner.html">Tutorial - Cleaning fossil data for the use in biogeography and palaeontology</a>
    </li>
    <li>
      <a href="../articles/qs_clean_coordinates.html">Quick start - Problematic records</a>
    </li>
    <li>
      <a href="../articles/qs_clean_dataset.html">Quick start - Problematic datasets</a>
    </li>
    <li>
      <a href="../articles/qs_clean_fossils.html">Quick start - Problematic fossils</a>
    </li>
    <li>
      <a href="../articles/qs_how_to_run.html">Quick start - How to run CoordinateCleaner</a>
    </li>
  </ul>
</li>
<li>
  <a href="../news/index.html">Changelog</a>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right"></ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      
      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header toc-ignore">
      <h1>Tutorial - Cleaning GBIF data for the use in biogeography</h1>
                        <h4 class="author">Alexander Zizka</h4>
            
            <h4 class="date">2018-07-25</h4>
      
      
      <div class="hidden name"><code>Cleaning_GBIF_data_with_CoordinateCleaner.Rmd</code></div>

    </div>

    
    
<div id="background" class="section level1">
<h1 class="hasAnchor">
<a href="#background" class="anchor"></a>Background</h1>
<p>Big data aggregators such as the Global Biodiversity Information Facility (GBIF, www.gbif.org) have vastly increased the public availability of species occurrence records, with GBIF alone comprising more than 800 million records across all taxonomic groups. The data provided via these sources have revolutionized scientific biogeography and are highly valuable for research. However, some issues exist concerning data quality, mostly because these data are comprised from a variety of different collection methods (museum specimens, scientific surveys, citizen science, population counts for conservation purposes and genetic barcoding among others) and different sources (museums, herbaria, collections of individual researchers, citizen science, photo apps) and digitized and edited by various people and algorithms at different points in time and space.</p>
<p>In this tutorial we provide a pipeline on how to clean occurrence records retrieved from GBIF (or any other database) using <em>CoordinateCleaner</em> and meta data. The tutorial includes major steps we consider necessary, but by no means is complete and we explicitly encourage you to explore your data further before use. For the tutorial we will use a data set of occurrence records of a single species (lion, <em>Panthera leo</em>) downloaded from GBIF. On this example we can gauge the quality of cleaning steps, because we already have a good idea where we expect lions to occur. Of course, usually for multi-species data sets we do not have this kind of information, and that is the whole point of the automated cleaning. You can easily follow the tutorial using your own data instead. For the tutorial we will assume a global macroecological analysis with a resolution of about 100km as downstream analyses. Remember to adjust test sensitivity, if your analyses have a coarser or finer resolution.</p>
<p>With this tutorial you will be able to:</p>
<ol style="list-style-type: decimal">
<li>Visualize the data and identify potential problems</li>
<li>Use  to automatically flag problematic records</li>
<li>Use GBIF provided meta-data to improve coordinate quality, tailored to your downstream analyses</li>
<li>Use automated cleaning algorithms of  to identify problematic contributing datasets</li>
</ol>
</div>
<div id="identifying-erroneous-coordinates-using" class="section level1">
<h1 class="hasAnchor">
<a href="#identifying-erroneous-coordinates-using" class="anchor"></a>Identifying erroneous coordinates using </h1>
<p>The <code>clean_coordinates</code> function is a wrapper function around all record-level tests of . The idea behind these tests is to use geographic gazetteers to identify records that are most likely erroneous (or very imprecise). We based the choice of tests on common problems observed in biological collection databases (see for example <span class="citation">(Maldonado et al., 2015)</span>), including assignment to country centroids, sea coordinate and outliers among others. You can get an overview over the individual tests using <code><a href="../reference/clean_coordinates.html">?clean_coordinates</a></code> or via the <a href="https://github.com/azizka/CoordinateCleaner/wiki">package wiki</a>. This tutorial assumes occurrence data in the format as downloaded from GBIF, for other formats you might need to adapt the column names. You might need to install some of the required packages for the tutorial using <code>install.packages</code>.</p>
<div id="install-coordinatecleaner" class="section level2">
<h2 class="hasAnchor">
<a href="#install-coordinatecleaner" class="anchor"></a>Install <code>CoordinateCleaner</code>
</h2>
<p>You can install the latest stable version of CoordinateCleaner from CRAN using <code>install.packages("CoordinateCleaner")</code>. Alternatively you can install the latest development version from GitHub using the devtools package. We recommend the latter, to stay up-to-date. Also, make sure to have the latest R version installed.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">install.packages</span>(<span class="st">"devtools"</span>)
<span class="kw">library</span>(devtools)

<span class="kw">install_github</span>(<span class="st">"azizka/CoordinateCleaner"</span>)</code></pre></div>
</div>
<div id="set-up-libraries-and-data" class="section level2">
<h2 class="hasAnchor">
<a href="#set-up-libraries-and-data" class="anchor"></a>Set up libraries and data</h2>
<p>You might need to confirm to install the rnaturalearth package when loading <code>CoordinateCleaner</code></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(dplyr)
<span class="kw">library</span>(ggplot2)
<span class="kw">library</span>(rgbif)
<span class="kw">library</span>(countrycode)
<span class="kw">library</span>(CoordinateCleaner)

<span class="co">#obtain data from GBIF via rgbif</span>
dat &lt;-<span class="st"> </span><span class="kw">occ_search</span>(<span class="dt">scientificName =</span> <span class="st">"Panthera leo"</span>, <span class="dt">limit =</span> <span class="dv">5000</span>, 
                  <span class="dt">return =</span> <span class="st">"data"</span>, <span class="dt">hasCoordinate =</span> T)

<span class="co"># names(dat) #a lot of columns</span>

<span class="co">#select columns of interest</span>
dat &lt;-<span class="st"> </span>dat <span class="op">%&gt;%</span>
<span class="st">  </span>dplyr<span class="op">::</span><span class="kw"><a href="http://dplyr.tidyverse.org/reference/select.html">select</a></span>(species, decimalLongitude, decimalLatitude, countryCode, individualCount,
         gbifID, family, taxonRank, coordinateUncertaintyInMeters, year,
         basisOfRecord, institutionCode, datasetName) </code></pre></div>
</div>
<div id="visualize-the-data-on-a-map" class="section level2">
<h2 class="hasAnchor">
<a href="#visualize-the-data-on-a-map" class="anchor"></a>Visualize the data on a map</h2>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#plot data to get an overview</span>
wm &lt;-<span class="st"> </span><span class="kw">borders</span>(<span class="st">"world"</span>, <span class="dt">colour=</span><span class="st">"gray50"</span>, <span class="dt">fill=</span><span class="st">"gray50"</span>)
<span class="kw">ggplot</span>()<span class="op">+</span><span class="st"> </span><span class="kw">coord_fixed</span>()<span class="op">+</span><span class="st"> </span>wm <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="dt">data =</span> dat, <span class="kw">aes</span>(<span class="dt">x =</span> decimalLongitude, <span class="dt">y =</span> decimalLatitude),
             <span class="dt">colour =</span> <span class="st">"darkred"</span>, <span class="dt">size =</span> <span class="fl">0.5</span>)<span class="op">+</span>
<span class="st">  </span><span class="kw">theme_bw</span>()</code></pre></div>
<div class="figure">
<img src="Cleaning_GBIF_data_with_CoordinateCleaner_files/figure-html/unnamed-chunk-4-1.png" alt="\label{fig:al}Occurrence records for Panthera leo obtained from GBIF." width="672"><p class="caption">
Occurrence records for Panthera leo obtained from GBIF.
</p>
</div>
<p>This map clearly indicates, that we need to prepare the data further, if we want them to represent the current day (or historic) distribution of lions.</p>
</div>
<div id="use-to-automatically-flag-problematic-records" class="section level2">
<h2 class="hasAnchor">
<a href="#use-to-automatically-flag-problematic-records" class="anchor"></a>Use  to automatically flag problematic records</h2>
<div id="option-a-using-the-clean_coordinates-wrapper-function" class="section level3">
<h3 class="hasAnchor">
<a href="#option-a-using-the-clean_coordinates-wrapper-function" class="anchor"></a>Option A) Using the <code>clean_coordinates</code> wrapper function</h3>
<p>As a first step we will run the automatic cleaning algorithm of CoordinateCleaner. The <code>clean_coordinates</code> function is a wrapper around a large set of automated cleaning steps to flag errors that are common to biological collections, including: sea coordinates, zero coordinates, coordinate - country mismatches, coordinates assigned to country and province centroids, coordinates within city areas, outlier coordinates and coordinates assigned to biodiversity institutions. You can switch on each test individually using logical flags, modify the sensitivity of most individual tests using the “.rad” arguments, and provide custom gazetteers using the “.ref” arguments. See <code><a href="../reference/clean_coordinates.html">?clean_coordinates</a></code> for help. To use the country - coordinate mismatch test we need to convert the country from ISO2 to ISO3 format.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#convert country code from ISO2c to ISO3c</span>
dat<span class="op">$</span>countryCode &lt;-<span class="st">  </span><span class="kw">countrycode</span>(dat<span class="op">$</span>countryCode, <span class="dt">origin =</span>  <span class="st">'iso2c'</span>, <span class="dt">destination =</span> <span class="st">'iso3c'</span>)

<span class="co">#flag problems</span>
dat &lt;-<span class="st"> </span><span class="kw">data.frame</span>(dat)
flags &lt;-<span class="st"> </span><span class="kw"><a href="../reference/clean_coordinates.html">clean_coordinates</a></span>(<span class="dt">x =</span> dat, <span class="dt">lon =</span> <span class="st">"decimalLongitude"</span>, <span class="dt">lat =</span> <span class="st">"decimalLatitude"</span>,
                          <span class="dt">countries =</span> <span class="st">"countryCode"</span>, 
                          <span class="dt">species =</span> <span class="st">"species"</span>,
                          <span class="kw">c</span>(<span class="st">"capitals"</span>, <span class="st">"centroids"</span>, <span class="st">"equal"</span>,
                            <span class="st">"gbif"</span>, <span class="st">"institutions"</span>,
                            <span class="st">"zeros"</span>, <span class="st">"countries"</span>)) <span class="co"># most test are on by default</span>
## Testing coordinate validity
## Flagged 0 records.
## Testing equal lat/lon
## Flagged 15 records.
## Testing zero coordinates
## Flagged 14 records.
## Testing country capitals
## Flagged 6 records.
## Testing country centroids
## Flagged 12 records.
## Testing country identity
## Flagged 173 records.
## Testing GBIF headquarters, flagging records around Copenhagen
## Flagged 0 records.
## Testing biodiversity institutions
## Flagged 0 records.
## Flagged 183 of 2300 records, EQ = 0.08.
<span class="kw">summary</span>(flags)
<span class="kw">plot</span>(flags)</code></pre></div>
<div class="figure">
<img src="Cleaning_GBIF_data_with_CoordinateCleaner_files/figure-html/unnamed-chunk-5-1.png" alt="\label{fig:automated}Records flagged by the automated cleaning." width="672"><p class="caption">
Records flagged by the automated cleaning.
</p>
</div>
<pre><code>## decimallatitude             val             equ             zer 
##              13               0              15              14 
##             cap             cen             con             gbf 
##               6              12             173               0 
##            inst         summary 
##               0             183</code></pre>
<p>The automatic test flagged 8% of the records. For the purpose of this tutorial we will exclude the flagged records, but in general it is recommendable to explore them further.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#Exclude problematic records</span>
dat.cl &lt;-<span class="st"> </span>dat[flags<span class="op">$</span>summary,]

<span class="co">#THe flagged records</span>
dat.fl &lt;-<span class="st"> </span>dat[<span class="op">!</span>flags<span class="op">$</span>summary,]</code></pre></div>
</div>
<div id="option-b-using-the-magrittr-pipe" class="section level3">
<h3 class="hasAnchor">
<a href="#option-b-using-the-magrittr-pipe" class="anchor"></a>Option B) Using the magrittr pipe (%&gt;%)</h3>
<p>Alternatively, you can run all tests implemented in  with a individual function and connect them using the magrittr pipe operator, which will directly result in a <code>data.frame</code> comprising only cleaned records.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"> <span class="co">#to avoid specifying it in each function</span>
<span class="kw">names</span>(dat)[<span class="dv">2</span><span class="op">:</span><span class="dv">3</span>] &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">"decimallongitude"</span>, <span class="st">"decimallatitude"</span>)

clean &lt;-<span class="st"> </span>dat<span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw"><a href="../reference/cc_val.html">cc_val</a></span>()<span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw"><a href="../reference/cc_equ.html">cc_equ</a></span>()<span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw"><a href="../reference/cc_cap.html">cc_cap</a></span>()<span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw"><a href="../reference/cc_cen.html">cc_cen</a></span>()<span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw"><a href="../reference/cc_coun.html">cc_coun</a></span>(<span class="dt">iso3 =</span> <span class="st">"countryCode"</span>)<span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw"><a href="../reference/cc_gbif.html">cc_gbif</a></span>()<span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw"><a href="../reference/cc_inst.html">cc_inst</a></span>()<span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw"><a href="../reference/cc_sea.html">cc_sea</a></span>()<span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw"><a href="../reference/cc_zero.html">cc_zero</a></span>()<span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw"><a href="../reference/cc_outl.html">cc_outl</a></span>()<span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw"><a href="../reference/cc_dupl.html">cc_dupl</a></span>()</code></pre></div>
</div>
</div>
</div>
<div id="improving-data-quality-using-gbif-meta-data" class="section level1">
<h1 class="hasAnchor">
<a href="#improving-data-quality-using-gbif-meta-data" class="anchor"></a>Improving data quality using GBIF meta-data</h1>
<p>That helped a lot, but unfortunately some unwanted records remain, especially within Europe (Fig. ). This is mostly because we have used the occurrence records uncritically and ignored the meta-data. GBIF offers a whole lot of useful meta-data which we will use now to further refine quality of our dataset. First we’ll remove coordinates with very low precision and from unsuitable data sources. We will remove all records with a precision below 100 km as this represent the grain size of our downstream analysis, but we recommend you to chose it based on your downstream analyses. We also exclude fossils as we are interested in recent distributions; and records from unknown sources, as we deem them not reliable enough.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#Remove records with low coordinate precision</span>
<span class="kw">hist</span>(dat.cl<span class="op">$</span>coordinateUncertaintyInMeters<span class="op">/</span><span class="dv">1000</span>, <span class="dt">breaks =</span> <span class="dv">20</span>)</code></pre></div>
<div class="figure">
<img src="Cleaning_GBIF_data_with_CoordinateCleaner_files/figure-html/unnamed-chunk-8-1.png" alt="\label{fig:automated}A histogram of the coordinate precision in the dataset.." width="672"><p class="caption">
A histogram of the coordinate precision in the dataset..
</p>
</div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">
dat.cl &lt;-<span class="st"> </span>dat.cl <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">filter</span>(coordinateUncertaintyInMeters<span class="op">/</span><span class="dv">1000</span> <span class="op">&lt;=</span><span class="st"> </span><span class="dv">100</span> <span class="op">|</span><span class="st"> </span><span class="kw">is.na</span>(coordinateUncertaintyInMeters))

<span class="co">#Remove unsuitable data sources, especially fossils </span>
<span class="co">#which are responsible for the majority of problems in this case</span>
<span class="kw">table</span>(dat<span class="op">$</span>basisOfRecord)
## 
##     FOSSIL_SPECIMEN   HUMAN_OBSERVATION MACHINE_OBSERVATION 
##                 440                1542                   3 
##         OBSERVATION  PRESERVED_SPECIMEN             UNKNOWN 
##                   1                 190                 124

dat.cl &lt;-<span class="st"> </span><span class="kw">filter</span>(dat.cl, basisOfRecord <span class="op">==</span><span class="st"> "HUMAN_OBSERVATION"</span> <span class="op">|</span><span class="st"> </span>
<span class="st">                         </span>basisOfRecord <span class="op">==</span><span class="st"> "OBSERVATION"</span> <span class="op">|</span>
<span class="st">                         </span>basisOfRecord <span class="op">==</span><span class="st"> "PRESERVED_SPECIMEN"</span>)</code></pre></div>
<p>In the next step we will remove records with suspicious individual counts. GBIF includes few records of absence (individual count = 0) and suspiciously high occurrence counts, which might indicate inappropriate data or data entry problems.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#Individual count</span>
<span class="kw">table</span>(dat.cl<span class="op">$</span>individualCount)</code></pre></div>
<pre><code>## 
##   0   1   2   3   4   5   6  15 
##   6 114  32   3   1   1   1   1</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dat.cl &lt;-<span class="st"> </span>dat.cl<span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">filter</span>(individualCount <span class="op">&gt;</span><span class="st"> </span><span class="dv">0</span> <span class="op">|</span><span class="st"> </span><span class="kw">is.na</span>(individualCount))<span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">filter</span>(individualCount <span class="op">&lt;</span><span class="st"> </span><span class="dv">99</span> <span class="op">|</span><span class="st"> </span><span class="kw">is.na</span>(individualCount)) <span class="co"># high counts are not a problem</span></code></pre></div>
<p>We might also want to exclude very old records, as they are more likely to be unreliable. For instance, records from before the second world war are often very imprecise, especially if they were geo-referenced based on political entities. Additionally old records might be likely from areas where species went extinct (for example due to land-use change).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#Age of records</span>
<span class="kw">table</span>(dat.cl<span class="op">$</span>year)</code></pre></div>
<pre><code>## 
## 1898 1905 1906 1911 1912 1913 1920 1923 1927 1928 1929 1930 1931 1936 1941 
##    2    7    1    7    7    1    2    1   17    8    8    4    2    2    4 
## 1948 1949 1951 1958 1959 1963 1964 1966 1967 1968 1969 1970 1972 1974 1978 
##   26    1    1    2    3    1    1    7    5    4    7    2    2    1    2 
## 1980 1981 1982 1983 1984 1985 1986 1987 1989 1990 1991 1992 1994 1995 1996 
##    6    1    2   11    6    2    2    2    8    1    3    4    4    4    9 
## 1997 1998 1999 2000 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 
##    5    9   76    2   11    5   22    9    6   23   23   28   30   49   56 
## 2012 2013 2014 2015 2016 2017 2018 
##   71   76  169  180  144  244   76</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">dat.cl &lt;-<span class="st"> </span>dat.cl<span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">filter</span>(year <span class="op">&gt;</span><span class="st"> </span><span class="dv">1945</span>) <span class="co"># remove records from before second world war</span></code></pre></div>
<p>On top of the geographic cleaning, we also want to make sure to only include species level records and records from the right taxon. The latter is not a problem in this case, as we only have one species, but it can be helpful for large datasets. Taxonomic problems such as spelling mistakes in the names or synonyms can be a severe problem. We’ll not treat taxonomic cleaning here, but if you need to, check out the <a href="https://ropensci.org/tutorials/taxize_tutorial.html">taxize R package</a> or the <a href="http://tnrs.iplantcollaborative.org/">taxonomic name resolution service</a> (plants only).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">table</span>(dat.cl<span class="op">$</span>family) <span class="co">#that looks good</span>
## 
## Felidae 
##    1444
dat.cl &lt;-<span class="st"> </span>dat.cl<span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw">filter</span>(family <span class="op">==</span><span class="st"> 'Felidae'</span>)

<span class="kw">table</span>(dat.cl<span class="op">$</span>taxonRank) <span class="co"># this is also good</span>
## 
##    SPECIES SUBSPECIES 
##        728        716</code></pre></div>
<p>We excluded almost 50% of the initial data points with the data cleaning, and the general picture has improved considerably. We confined the records mostly to what can be considered current day distribution of the species of interest (Fig. ).</p>
<p>We have, however, also lost quite a number of records. In general, there is no “one-size-fits-it-all” for data quality of geographic species occurrence records. Of course highest coordinate precision is desirable, but what is acceptable will strongly depend on the downstream analyses. For species distribution modelling, usually high precision is necessary e.g. 1-10 km, but for other analyses such as biogeographic reconstructions using tectonic plates, a record might be considered good enough quality, as long as it is on the right continent. As another example for conservation purposes it might be sufficient to know that a species is present within a certain country.</p>
</div>
<div id="improving-data-quality-using-external-information" class="section level1">
<h1 class="hasAnchor">
<a href="#improving-data-quality-using-external-information" class="anchor"></a>Improving data quality using external information</h1>
<p>Figure  shows the success of automated cleaning. However, three records within Europe remain. A short inspection of the data suggests that these are a dubious human observation and five specimens, potentially assigned to their specimen location, or fossils with misclassified meta-data. One option to automatically flag these records is to rerun the outlier test on the cleaned data. However, this would most likely also flag the isolated Indian population (which is a true presence) as problematic. Another alternative is to use additional knowledge or the study outline for additional cleaning, using species defined ranges (for animals for example the <a href="http://www.iucnredlist.org/technical-documents/spatial-data">IUCN range maps</a> or for plants the botanical countries of the <a href="http://wcsp.science.kew.org/home.do">World Checklist of selected plant families</a>. A third alternative is to exclude records outside a certain study extent. In our example the latter is the easiest solution because we know that lions do not occur in high latitudes any more.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#exclude based on study area</span>
dat.fin &lt;-<span class="st"> </span><span class="kw">filter</span>(dat.cl, decimalLatitude <span class="op">&lt;</span><span class="st"> </span><span class="dv">40</span>)</code></pre></div>
<div class="figure">
<img src="Cleaning_GBIF_data_with_CoordinateCleaner_files/figure-html/unnamed-chunk-13-1.png" alt="\label{fig:final}The dataset of occurrence of lions after different cleaning phases." width="672"><p class="caption">
The dataset of occurrence of lions after different cleaning phases.
</p>
</div>
</div>
<div id="identifying-problematic-data-sets" class="section level1">
<h1 class="hasAnchor">
<a href="#identifying-problematic-data-sets" class="anchor"></a>Identifying problematic data sets</h1>
<p>Some types of potentially problematic coordinates can cause bias, but are not identifiable on record-level if the relevant meta-data are missing. This is especially the case if the erroneous records have been combined with precise GPS-based point occurrences into datasets of mixed precision. Two important cases are: (A) coordinate conversion errors based on the misinterpretation of the degree sign as decimal delimiter and (B) data derived from rasterized data collection designs (e.g. presence in a 50x50 km grid cell).  implements two algorithms to identify these problems on a dataset level.</p>
<div id="identify-dataset-with-ddmm-to-dd-dd-conversion-error" class="section level2">
<h2 class="hasAnchor">
<a href="#identify-dataset-with-ddmm-to-dd-dd-conversion-error" class="anchor"></a>Identify dataset with ddmm to dd.dd conversion error</h2>
<p>We will first run the test for erroneous data conversion due to the misinterpretation of the degree sign as decimal delimiter. We will use the <code>cd_ddmm</code> function, alternatively, you can use the <code>clean_dataset</code> wrapper. See supplementary material S1 for a detailed description of the algorithm and implementation of the test. You can control the output of the function via the <code>value</code> argument.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">out.ddmm &lt;-<span class="st"> </span><span class="kw"><a href="../reference/cd_ddmm.html">cd_ddmm</a></span>(dat.cl, <span class="dt">lon =</span> <span class="st">"decimalLongitude"</span>, <span class="dt">lat =</span> <span class="st">"decimalLatitude"</span>, 
                    <span class="dt">ds =</span> <span class="st">"species"</span>, <span class="dt">diagnostic =</span> T, <span class="dt">diff =</span> <span class="dv">1</span>,
                    <span class="dt">value =</span> <span class="st">"dataset"</span>)</code></pre></div>
<p><img src="Cleaning_GBIF_data_with_CoordinateCleaner_files/figure-html/unnamed-chunk-14-1.png" width="672"></p>
<p>This looks good. The test indicates a slightly higher fraction of records with decimals below .60 than expected at random, but this is within the expected range and thus the test indicates no bias, which is confirmed by the diagnostic plot. In the case of a strong bias, the green points would be clustered in the bottom left quarter of the plot.</p>
</div>
<div id="test-for-rasterized-sampling" class="section level2">
<h2 class="hasAnchor">
<a href="#test-for-rasterized-sampling" class="anchor"></a>Test for rasterized sampling</h2>
<p>As a second step we will use the <code>cd_round</code> function to identify datasets with a significant proportion of coordinates that have been collected in large scale lattice designs. These records might have a low precision and might therefore be problematic for some analyses. For instance presence derived from a 1 degree grid of a national atlas might be to coarse for small scale species distribution models.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">2</span>), <span class="dt">mar =</span> <span class="kw">rep</span>(<span class="dv">2</span>, <span class="dv">4</span>))
out.round &lt;-<span class="st"> </span><span class="kw"><a href="../reference/cd_round.html">cd_round</a></span>(dat.fin, <span class="dt">lon =</span> <span class="st">"decimalLongitude"</span>, 
                      <span class="dt">lat =</span> <span class="st">"decimalLatitude"</span>, 
                      <span class="dt">ds =</span> <span class="st">"species"</span>,
                      <span class="dt">value =</span> <span class="st">"dataset"</span>,
                      <span class="dt">T1 =</span> <span class="dv">7</span>,
                      <span class="dt">graphs =</span> T)
## Testing for rasterized collection</code></pre></div>
<div class="figure">
<img src="Cleaning_GBIF_data_with_CoordinateCleaner_files/figure-html/unnamed-chunk-15-1.png" alt="\label{fig:final}Diagnostic plots testing for rasterized sampling or excessive rounding. The left panel shows histograms of the record distribution, the right panel shows the autoorrelation plots. The upper panel shows longitude, the lower panel shows latitude. The logical flag in the heading of the right panel indicates the binary flag." width="672"><p class="caption">
Diagnostic plots testing for rasterized sampling or excessive rounding. The left panel shows histograms of the record distribution, the right panel shows the autoorrelation plots. The upper panel shows longitude, the lower panel shows latitude. The logical flag in the heading of the right panel indicates the binary flag.
</p>
</div>
<p>These results look good. The dataset does not show rasterized collection schemes (see Supplementary material S1 for examples of biased datasets). The test has detected and flagged some small scale and low intensity periodicity in the longitude coordinates, however, the entire dataset is only flagged if both longitude and latitude show a pattern (as expected from rasterized sampling). You can modify the test sensitivity using various arguments. See <code><a href="../reference/cd_round.html">?cd_round</a></code> for more information.</p>
<p>The lion dataset is relatively small and consistent, at least in the way that it only comprises on species. For larger scale analyses you might need to deal with larger datasets, composed from a larger variety of sources.</p>
</div>
<div id="references" class="section level2">
<h2 class="hasAnchor">
<a href="#references" class="anchor"></a>References</h2>
<!-- # Testing larger databses comprised from multiple datasets -->
<!-- ## Load data -->
<!-- First we will download a larger example database that includes multiple contributing datasets with a sufficient number of records each. Here will use records from all African mammals as example. The download takes some time, alternatively, you can download the data via \url{www.gbif.org}. Based on the assumptions of the dataset-level tests (See supplementary material S1), we will exclude very small datasets with less than 100 individual records or less than 50 unique locations or spanning less than 2 degrees from the analyses. -->
<!-- ```{r, echo = F, eval = TRUE, warning = F, message = F} -->
<!-- dat <- read_csv("mammal_example.csv", guess_max = 100000) -->
<!-- #identify datasets with < 100 records and  -->
<!-- excl1 <- table(dat$datasetKey) -->
<!-- excl1 <-excl1[excl1>100] -->
<!-- #identify datasets with  less than 50 unique locations -->
<!-- excl2 <- dat[!duplicated(dat[,c("decimalLongitude", "decimalLatitude", "datasetKey")]),] -->
<!-- excl2 <- table(excl2$datasetKey) -->
<!-- excl2 <- excl2[excl2 > 50] -->
<!-- # exclude small datasets -->
<!-- dat <- dat%>% -->
<!--   filter(datasetKey %in% names(excl1))%>% -->
<!--   filter(datasetKey %in% names(excl2)) -->
<!-- dat <- dplyr::select(dat, decimalLongitude, decimalLatitude, datasetKey)%>% -->
<!--   as.data.frame() -->
<!-- ``` -->
<!-- ```{r, eval = F, message = F} -->
<!-- #download data, this can take some time -->
<!-- dat <- occ_search(scientificName = "Mammalia", limit = 200000, continent = "africa", -->
<!--                   return = "data", hasCoordinate = T) -->
<!-- #select relevant columns -->
<!-- dat <- select(dat, decimalLongitude, decimalLatitude, datasetKey)%>% -->
<!--   as.data.frame() -->
<!-- #identify datasets with < 300 records and  -->
<!-- excl1 <- table(dat$datasetKey) -->
<!-- excl1 <-excl1[excl1>100] -->
<!-- #identify datasets with  less than 10 unique locations -->
<!-- excl2 <- dat[!duplicated(dat[,c("decimalLongitude", "decimalLatitude", "datasetKey")]),] -->
<!-- excl2 <- table(excl2$datasetKey) -->
<!-- excl2 <- excl2[excl2 > 50] #at more than 50 different locations -->
<!-- # exclude smal datasets -->
<!-- dat <- dat%>% -->
<!--   filter(datasetKey %in% names(excl1))%>% -->
<!--   filter(datasetKey %in% names(excl2)) -->
<!-- dat <- select(dat, decimalLongitude, decimalLatitude, datasetKey)%>% -->
<!--   as.data.frame() -->
<!-- ``` -->
<!-- ## Identify dataset with ddmm to dd.dd conversion error -->
<!-- We will first run the `cd_ddmm` test again, alternatively, you can use the `clean_dataset` wrapper. You can control the output of the function via the `value` argument. -->
<!-- ```{r, warning = F, message = F} -->
<!-- # output with a summary for each dataset -->
<!-- out.ddmm <- cd_ddmm(dat, lon = "decimalLongitude", lat = "decimalLatitude",  -->
<!--                     ds = "datasetKey", diff = 1,  -->
<!--                     value = "dataset") -->
<!-- head(out.ddmm) -->
<!-- ``` -->
<!-- The result suggest that 0 dataset (0%) including 0 records (NaN %) might include a significant portion of records with potentially erroneous coordinates; 0 datasets where to small to be tested -->
<!-- We will have a closer look at the flagged dataset and its analyses matrix by retuning the test on the dataset individually. This is a relatively small dataset (< 10000 records) thus we can decrease the size of the analyses matrix to make the plot more easily interpretable. -->
<!-- ```{r, warning = F, message = F} -->
<!-- dat.sub <- dat%>% -->
<!--   filter(datasetKey %in% rownames(out.ddmm[!out.ddmm$pass,])) -->
<!-- cd_ddmm(dat.sub, lon = "decimalLongitude", lat = "decimalLatitude",  -->
<!--                     ds = "datasetKey", diff = 1,  -->
<!--                     value = "dataset", diagnostic = T, mat.size = 100) -->
<!-- ``` -->
<!-- There is indeed a clustering of records with decimals below 0.6! This might indicate conversion bias. To learn more we will have a look at the coordinates in the dataset. -->
<!-- ```{r} -->
<!-- table(dat.sub$decimalLongitude) -->
<!-- ``` -->
<!-- It seems the problem here is rather a high number of rounded coordinates, inflating the number of decimals below 0.6, and not a conversion error. We'll get some more information from GBIF.  -->
<!-- ```{r, echo = T, message = F} -->
<!-- uid <- dat.sub%>% -->
<!--   dplyr::select(datasetKey)%>% -->
<!--   unlist()%>% -->
<!--   unique() -->
<!-- lapply(uid, function(k) rgbif::datasets(uuid = k, type = "data")$data$description) -->
<!-- ``` -->
<!-- The flagged dataset is a global mammal dataset form the collection of the American Museum of Natural History. The results are not fully decisive. The contribution of the dataset to our total dataset is rather small, so we could decide to drop the relevant records. In this case however, based on the analyses matrix, the coordinate distribution and the source, we  suggest to keep the dataset for further analyses. -->
<!-- ## Identify datasets with rasterization bias -->
<!-- As a second step we will use the `cd_round` function to identify datasets with a significant proportion of coordinates that have undergone decimal rounding or that have been collected in rasterized designs. We can control the output value and exclude flagged datasets as above. -->
<!-- ```{r, echo = T, warning = F, eval = T} -->
<!-- out.round <- cd_round(dat, lon = "decimalLongitude",  -->
<!--                       lat = "decimalLatitude",  -->
<!--                       ds = "datasetKey", -->
<!--                       value = "dataset", -->
<!--                       T1 = 9, -->
<!--                       graphs = FALSE) -->
<!-- out.round$dataset <- rownames(out.round) -->
<!-- ``` -->
<!-- The result suggest that 0 data sets (0%) including 0 records (NaN%) show a conspicuous pattern of periodicity. Thus more than half the records are flagged by the test. A look a the diagnostic plots (you can see them by rerunning the test with `graphs = TRUE`, not shown here) shows that indeed most of the datasets do not seem to contain exclusively GPS coordinates but rather either concatenated, rounded, or rasterized coordinates (the isolated peaks in the example plot). This is expected, since we downloaded all occurrences without restrictions and thus will also include for instance old records with only rough georeferencing.  Remember also, that imprecise, rounded coordinates might not be a problem, depending on the resolution of the downstream analyses. Since we downloaded all mammals for Africa, we are probably interested in a large scale analyses, an will thus not need a coordinate precision higher than 100 km. To account for this we rerun the `cd_round` test with different settings, only flagging datasets with periodicities at more than 1 degree. -->
<!-- ```{r, echo = T, warning = F, eval = T} -->
<!-- out.round <- cd_round(dat, lon = "decimalLongitude",  -->
<!--                       lat = "decimalLatitude",  -->
<!--                       ds = "datasetKey", -->
<!--                       value = "dataset", -->
<!--                       T1 = 9, -->
<!--                       reg.dist.min = 1, -->
<!--                       graphs = FALSE) -->
<!-- out.round$dataset <- rownames(out.round) -->
<!-- out.round$summary -->
<!-- ``` -->
<!-- So at this scale none of the datasets shows periodicity. If you need a higher resolution you can easily exclude erroneous records using `value == "clean"`, and we can proceed to the downstream analyses. Note however, that a passed test does not mean that there are no rounded coordinates in the data (we know there are), it just indicates that there are now returning patterns, which would be indicative of a rasterized sampling or rounding of many coordinates over a certain geographic range. -->
<div id="refs" class="references">
<div id="ref-Maldonado">
<p>Maldonado, C., Molina, C. I., Zizka, A., Persson, C., Taylor, C. M., Albán, J., Chilquillo, E., et al. (2015). Estimating species diveristy and distribution in the era of Big Data: To what extent can we trust public databases. <em>Glob Ecol Biogeogr</em>, <em>24</em>(8), 973–984.</p>
</div>
</div>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
        <div id="tocnav">
      <h2 class="hasAnchor">
<a href="#tocnav" class="anchor"></a>Contents</h2>
      <ul class="nav nav-pills nav-stacked">
<li><a href="#background">Background</a></li>
      <li>
<a href="#identifying-erroneous-coordinates-using">Identifying erroneous coordinates using </a><ul class="nav nav-pills nav-stacked">
<li><a href="#install-coordinatecleaner">Install <code>CoordinateCleaner</code></a></li>
      <li><a href="#set-up-libraries-and-data">Set up libraries and data</a></li>
      <li><a href="#visualize-the-data-on-a-map">Visualize the data on a map</a></li>
      <li><a href="#use-to-automatically-flag-problematic-records">Use  to automatically flag problematic records</a></li>
      </ul>
</li>
      <li><a href="#improving-data-quality-using-gbif-meta-data">Improving data quality using GBIF meta-data</a></li>
      <li><a href="#improving-data-quality-using-external-information">Improving data quality using external information</a></li>
      <li>
<a href="#identifying-problematic-data-sets">Identifying problematic data sets</a><ul class="nav nav-pills nav-stacked">
<li><a href="#identify-dataset-with-ddmm-to-dd-dd-conversion-error">Identify dataset with ddmm to dd.dd conversion error</a></li>
      <li><a href="#test-for-rasterized-sampling">Test for rasterized sampling</a></li>
      <li><a href="#references">References</a></li>
      </ul>
</li>
      </ul>
</div>
      </div>

</div>


      <footer><div class="copyright">
  <p>Developed by Alexander Zizka.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="http://pkgdown.r-lib.org/">pkgdown</a>.</p>
</div>

      </footer>
</div>

  

  </body>
</html>
