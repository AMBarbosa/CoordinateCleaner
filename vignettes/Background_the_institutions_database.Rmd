---
title: "Background - The institutions database"
output: 
  html_document: 
    fig_caption: yes
bibliography: CoordinateCleaner.bib
---

```{r setup, include=FALSE, message = F, warning = FALSE}
library(tidyverse)
library(CoordinateCleaner)
library(raster)
library(viridis)
library(caret)
library(countrycode)
library(speciesgeocodeR)
```

```{r, echo = FALSE}
# A function for generating captions and cross-references

fig <- local({
    i <- 0
    list(
        cap=function(refName, text, center=FALSE, col="black", inline=FALSE) {
            i <<- i + 1
            ref[[refName]] <<- i
            css_ctr <- ""
            if (center) css_ctr <- "text-align:center; display:inline-block; width:100%;"
            cap_txt <- paste0("<span style=\"color:", col, "; ", css_ctr, "\">Figure ", i, ": ", text , "</span>")
            anchor <- paste0("<a name=\"", refName, "\"></a>")
            if (inline) {
                paste0(anchor, cap_txt)    
            } else {
                list(anchor=anchor, cap_txt=cap_txt)
            }
        },
        
        ref=function(refName, link=FALSE, checkRef=TRUE) {
            
            ## This function puts in a cross reference to a caption. You refer to the
            ## caption with the refName that was passed to fig$cap() (not the code chunk name).
            ## The cross reference can be hyperlinked.
            
            if (checkRef && !refName %in% names(ref)) stop(paste0("fig$ref() error: ", refName, " not found"))
            if (link) {
                paste0("<A HREF=\"#", refName, "\">Figure ", ref[[refName]], "</A>")
            } else {
                paste0("Figure ", ref[[refName]])
            }
        },
        
        ref_all=function(){
            ## For debugging
            ref
        })
})

## This chunk replaces the default hook for processing plots. It achieves the purposes,
## of laying out auto-numbered captions, but other functionality may be gone.

library(knitr)
knit_hooks$set(plot = function(x, options) {
    sty <- ""
    if (options$fig.align == 'default') {
        sty <- ""
    } else {
        sty <- paste0(" style=\"text-align:", options$fig.align, ";\"")
    }
    
    if (is.list(options$fig.cap)) {
        ## options$fig.cap is a list returned by the function fig$cap()
        str_caption <- options$fig.cap$cap_txt
        str_anchr <- options$fig.cap$anchor
    } else {
        ## options$fig.cap is a character object (hard coded, no anchor)
        str_caption <- options$fig.cap
        str_anchr <- ""
    }
    
    paste('<figure', sty, '>', str_anchr, '<img src="',
        opts_knit$get('base.url'), paste(x, collapse = '.'),
        '"><figcaption>', str_caption, '</figcaption></figure>',
        sep = '')
    
})

## This chucnk will read through *this* Rmd file, and attempt to extract all of the 
## labels (not caption text) used for Figure captions. These labels are used
## as anchors, so scanning through the document now will allow us to create cross references
## before the caption actually appears. 

## Get the name of this Rmd file
rmdFn <- knitr::current_input()  # filename of input document

## Read lines and close connection
rmdCon <- file(rmdFn, open = "r")
rmdLines <- readLines(rmdCon)
close(rmdCon)

## Pull out all occurences of at least one back tick, followed 
## by any number of characters, followed by fig$cap (all on one line)
figscap_idx <- grep("`+(.*)fig\\$cap", rmdLines)
rmdLines <- rmdLines[figscap_idx]

## Get rid of everything up until the start of the caption label
## This presumes the caption label is the first argument of fig$cap()
## E.g., fig.cap = fig$cap("my_label", ...)
rmdLinesSansPre <- sub("(.*)fig\\$cap(.*?)[\"']", "", rmdLines)

## Identify everything up until the first quote
match_data <- regexpr("(.*?)[\"']", rmdLinesSansPre)

## Reduce the length by one, because we're not interested in the final quote
attr(match_data, "match.length") <- attr(match_data, "match.length") - 1

## Extract
fig_labels <- regmatches(rmdLinesSansPre, match_data, invert=FALSE)

if (length(fig_labels) > 0) {

    ## Test for duplicates
    if (anyDuplicated(fig_labels) > 0) stop("Duplicate caption labels detected")
    
    ## Create a named list of Figure numbers
    ref <- as.list(1:length(fig_labels))
    names(ref) <- fig_labels
}    


```


# A global gazetteer of biodiversity institutions
```{r, echo = F, message = FALSE, warning = FALSE}
data(institutions)
institutions <- filter(institutions, !is.na(decimallongitude))
institutions$source <- trimws(institutions$source)
```

## Background
Most of the geographic species occurrence records publicly available from aggregated databases such as the Global Biodiversity Information Facility (GBIF), are either based on collected specimens stored in a museum, university, botanical garden, herbarium or zoo, or on human observations, e.g. vegetation surveys or citizen science projects. A relatively common error in the geographic information of these records are coordinates assigned to the physical location of the institution hosting the specimen. The reasons for these errors may include among others individuals escaped from horticulture, specimens erroneously geo-reference to their physical location as well as records based on pictures taken by laymen in zoos or botanical gardens. These records are problematic as the conditions at these locations do not represent the species' natural habitat and might in fact differ considerably from them.

To identify these records, CoordinateCleaner includes a novel geo-referenced global database of biodiversity institutions - defined here as institutions that generally are concerned with biodiversity research and/or hosting collections of living or mounted biological specimens. We implement a cleaning check using this database as gazetteer in the `cc_inst` function and the `institutions` argument of the `clean_coordinates` function of the *CoordinateCleaner* R-package. Furthermore, we hope that this database can prove useful beyond cleaning geographic records, for instance to assess sampling biases in biological collections.


## Data compilation
We compiled names of biodiversity institutions from six different sources (`r fig$ref("fig_sources", link = TRUE)`) [@BGCI-BotanicGardensConservationInternational2017; @IndexHerbariorum2017;@TheGlobalRegistryofBiodiversityRepositories2017; @Wikipedia2017; @GlobalBiodiveristyInformationFacility2017; @GeoNames2017] and geo-referenced them using the Google maps API via the ggmap package in R [@Kahle2013] using institution names and, if this yielded no results the institutions address. For those records that did not yield any results we used opencage via the opencage R-package [@Salmon2017] for geo-referencing. We manually geo-referenced those institutions that could not be geo-referenced automatically (c. 50%) using the WWW and Google earth [@GoogleInc2017]. In total the database comprises almost 9700 geo-referenced institutions (and another 2500 entries for which geo-referencing was not possible, either to problems with non-English names or geographic ambiguities). The spatial extent of the database is global (`r fig$ref("fig_raster", link = TRUE)`), but we acknowledge that there is a focus on English-speaking countries and countries using the Roman alphabet (See `r fig$ref("fig_continent", link = TRUE)` and  `r fig$ref("fig_country", link = TRUE)`). This is partly a bias due to the data compilation process. We hope that this bias can be overcome by future contributions to the database from researchers in non-English speaking and non-Roman alphabet countries. In general, we acknowledge that the database may not be complete and created a webmask at (http://biodiversity-institutions.surge.sh/) were researchers can easily submit their institution or a comment on an existing institution. The webpage also includes an overview on the institutions included in the dataset.


```{r fig1, echo = F, evaluate = T, warning = F, fig.show = T, fig.cap = fig$cap("fig_sources", "The contribution of different sources for entries in the `institutions` database presented in this study. All entries were georeferenced."), fig.height = 4}
plo <- institutions

plo$source <- factor(plo$source, levels = names(sort(table(plo$source))))

ggplot(data = plo)+
  geom_bar(aes(x = source))+
  xlab("Source")+
  ylab("Count")+
  theme_bw()
```



## Data structure
In addition to  the name and geographic coordinates for each institution, the database includes information on the type of the institutions ("type", e.g. "herbarium" or "university", see `r fig$ref("fig_continent", link = TRUE)`), the source from where we obtained the name of the institution ("source"), the precision of the coordinates ("geocoding.precision.m" and "geocoding.issue") as well as the city and address (when available, "city" and "address"). The quality of the meta-data might vary among different sources). Furthermore, the database includes a column identifying if the respective institution is located within a protected area [@UNEP-WCMCandIUCN2017], and if this is the case, the World Database of Protected Areas ID of the respective protected area (WDPA, shape file available at: https://www.protectedplanet.net/). We include this flag, as biodiversity institutions within protected areas might or might not be relevant for coordinate cleaning, depending on downstream analyses.




```{r fig2, echo = F, evaluate = T, warning = F, fig.show = T, fig.cap = fig$cap("fig_raster", "Global density of biodiversity institutions in the `institutions` database.")}
#number per 100km x 100 km grid cell
#reference raster
ras <- raster::raster("C:/Users/az64mycy/Dropbox (iDiv)/research_projects/29_CoordinateCleaner/analyses/input/ANNUAL_NDVI.tif")

#projections
wgs1984 <- CRS("+proj=longlat +ellps=WGS84 +datum=WGS84 +no_defs")
behr <- CRS('+proj=cea +lon_0=0 +lat_ts=30 +x_0=0 +y_0=0 +datum=WGS84 +ellps=WGS84 +units=m +no_defs')

#select and reproject institutions
abu <- institutions%>%
  dplyr::select(species = type, decimallongitude, decimallatitude)

abu.b <- abu%>%
  dplyr::select(decimallongitude, decimallatitude)%>%
  sp::SpatialPoints(proj4string = wgs1984)%>%
  spTransform(behr)


abu <- data.frame(abu$species, coordinates(abu.b))

abu <- abu%>%
  speciesgeocodeR::RichnessGrid(ras = ras)

abu <- raster::rasterToPoints(abu)%>%
  data.frame()


data(landmass)
proj4string(landmass) <- wgs1984
lm <- sp::spTransform(landmass, behr)
lm <- suppressMessages(fortify(lm))

ggplot()+
  geom_polygon(data = lm, aes(x = long, y = lat, group = group), fill = "grey80")+
  geom_raster(data = abu, aes(x = x, y = y, fill = layer))+
  scale_fill_gradient2(low = "blue", mid = "yellow", high = "red", midpoint = 3, name = "Number of\ninstitutions")+
  xlab("Longitude")+
  ylab("Latitude")+
  theme_bw()+
  coord_fixed()+
  theme(axis.text = element_blank(),
        axis.ticks = element_blank(),
        strip.background=element_blank(),
        legend.position = c(0.09, 0.35))

```



```{r fig3, echo = F, evaluate = T, warning = F, fig.show = T, fig.cap = fig$cap("fig_continent", "The number of biodiversity institutions per continent.")}
#Institutions per continent
cont <- institutions%>%
  mutate(continent = countrycode(country, origin = "iso3c", destination = "continent"))


sor <- cont%>%
  group_by(continent)%>%
  summarize(numb = n())%>%
  arrange(numb)


plo <- cont%>%
  mutate(continent = factor(cont$continent, levels = sor$continent))%>%
  filter(!is.na(continent))%>%
  filter(!is.na(type))
  

ggplot(data = plo)+
  geom_bar(aes(x = continent))+
  theme(axis.text= element_text(angle = 90, size = 5))+
  facet_wrap(~type, ncol = 2)+
  ylab("Count")+
  xlab("Institution type")+
  theme_bw()

```



```{r fig4, echo = F, evaluate = T, warning = F, fig.show = T, fig.cap = fig$cap("fig_country", "The top ten countries based on the number of hosted biodiversity institutions in the `institutions` database."), fig.height = 4}
#institutions per country
sor <- institutions%>%
  group_by(country)%>%
  summarize(numb = n())%>%
  arrange(numb)

sor <- sor[(nrow(sor) - 10):nrow(sor),]

sor2 <- sor %>%
  mutate(country = countrycode::countrycode(country, origin = "iso3c", destination = "country.name.en"))

plo <- institutions%>%
  filter(!is.na(country))%>%
  filter(country %in% sor$country)%>%
  mutate(country = countrycode::countrycode(country, origin = "iso3c", destination = "country.name.en"))


plo <- plo%>%
  mutate(country = factor(plo$country, levels = sor2$country))


plo$country <- gsub("United Kingdom of Great Britain and Northern Ireland", "UK", plo$country)
plo$country <- gsub("United States of America", "USA", plo$country)

plo <- plo%>%
  mutate(country = factor(plo$country, levels = c(sor2$country[1:8], "UK", "USA")))

ggplot(data = plo)+
  geom_bar(aes(x = country))+
  theme(axis.text= element_text(angle = 90, size = 5))+
  ylab("Count")+
  theme_bw()+
  theme(axis.title.x = element_blank())
```

## Data accessability
The database is open-source and available as R data file (.rda) as part of the *CoordinateCleaner* package either from [CRAN](https://cran.r-project.org/web/packages/CoordinateCleaner/index.html) or [GitHub](https://github.com/ropensci/CoordinateCleaner) under a CC-BY license. We acknowledge, that this database is not complete and can constantly be improved, any feedback can be provided via the GitHub page of \emph{CoordinateCleaner} (https://github.com/ropensci/CoordinateCleaner/). 

# References
